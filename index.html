<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI-based Driver Monitoring</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/primer-css/21.0.1/build.css">
    <link rel="stylesheet" href="assets/style.css">
    <script src="assets/script.js" defer></script>
</head>
<body>
    <div class="container-lg px-3 my-5">
        <div class="logos">
            <a href="https://islab.disco.unimib.it/" target="_blank"><img src="assets/islab_web.png" alt="ISLab Logo" class="logo" height=50px></a>
            <a href="http://www.ivl.disco.unimib.it/" target="_blank"><img src="assets/ivl-mini.jpg" alt="IVL Logo" class="logo" height=50px></a>
        </div>
        <h1>AI-based Driver Monitoring</h1>
        <p class="authors">
        Luigi Celona<sup>1</sup>&nbsp;&nbsp;&nbsp;Simone Bianco<sup>2</sup>&nbsp;&nbsp;&nbsp; Paolo Napoletano<sup>1</sup>
        </p>
        <p class="affiliations">
            <sup>1</sup>Intelligent Sensing Laboratorry, University of Milano-Bicocca, Milan, Italy
            <br>
            <sup>2</sup>Imaging and Vision Laboratory, University of Milano-Bicocca, Milan, Italy
        </p>
<br>
<p class="f4">This research aims to develop an efficient, non-invasive driver monitoring system that detects distraction and stress in real time, seamlessly adapting to different vehicles without requiring extensive calibration. By integrating multi-modal data processing into a compact, embedded solution, the project enhances road safety while enabling scalable applications across the automotive and transportation sectors, ultimately contributing to safer and more sustainable driving.</p>
<a href="https://drive.google.com/file/d/1bXPUOQSbxyB1-gZfEKEAyPtiS7pQvY9G/view?usp=sharing" download="project_description.pdf">Download the detailed project description</a>
<br>



<h2>Demo</h2>
<div class="container">
    <div class="video-wrapper">
        <iframe src="https://drive.google.com/file/d/1IVu3mwb67fY8kYxvWcKCaPiIQzQZw4qe/preview" 
                    allow="autoplay">
        </iframe>
    </div>
    <div class="description">
        <p><strong>The demonstration features a driving session using our simulator.</strong></p>
            <p>The board processes video frames captured by the RGB camera with the designed model and displays predictions for each frame on an LCD monitor (for illustration purposes only; in the final version, predictions will be transmitted to the car's black box).</p>
            <p>Each prediction corresponds to one of 22 labels.</p>
            <table>
        <thead>
            <tr>
                <th>No.</th>
                <th>Action</th>
                <th>No.</th>
                <th>Action</th>
                <th>No.</th>
                <th>Action</th>
                <th>No.</th>
                <th>Action</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>0</td> <td>Normal driving</td> <td>6</td> <td>Texting (right)</td> 
                <td>12</td> <td>Smoking (left)</td> <td>18</td> <td>Operating GPS</td>
            </tr>
            <tr>
                <td>1</td> <td>Sleeping</td> <td>7</td> <td>Hair / makeup</td> 
                <td>13</td> <td>Smoking (right)</td> <td>19</td> <td>Reaching behind</td>
            </tr>
            <tr>
                <td>2</td> <td>Yawning</td> <td>8</td> <td>Looking left</td> 
                <td>14</td> <td>Smoking (mouth)</td> <td>20</td> <td>Hands off the steering wheel</td>
            </tr>
            <tr>
                <td>3</td> <td>Talk with cellphone (left)</td> <td>9</td> <td>Looking right</td> 
                <td>15</td> <td>Drinking / Eating (left)</td> <td>21</td> <td>Talking to passenger</td>
            </tr>
            <tr>
                <td>4</td> <td>Talk with cellphone (right)</td> <td>10</td> <td>Looking up</td> 
                <td>16</td> <td>Drinking / Eating (right)</td> <td></td> <td></td>
            </tr>
            <tr>
                <td>5</td> <td>Texting (left)</td> <td>11</td> <td>Looking down</td> 
                <td>17</td> <td>Adjusting radio</td> <td></td> <td></td>
            </tr>
        </tbody>
    </table>
    </div>
</div>

<h2>Source Code</h2>
        At the following <a href="https://github.com/CeLuigi/DBMNet">link</a> is available the official PyTorch implementation of the method proposed in the paper ‚ÄúCross-Camera Distracted Driver Classification through Feature Disentanglement and Contrastive Learning‚Äù.
        The project focuses on robust distracted driver recognition using a multi-view, multi-task learning framework. The proposed approach jointly learns:
        <ul>
      <li>Driver action classification (22 classes)</li>
      <li>Camera view classification (3 views)</li>
        </ul>
and leverages triplet-based metric learning to improve generalization across drivers, viewpoints, and illumination conditions (day/night).

<h2>üìö References</h2>
<p>Click "Show LaTeX" to reveal citations. Click "üìã Copy" to copy the LaTeX code.</p>

<ul class="list-style-none">
<!-- Reference 1 -->
    <li class="Box Box--spacious p-3 mb-3">
        <details>
            <summary class="f4">üìñ Bani, M., Bianco, S., Celona, L., Napoletano, P., Russo, S., Sarn√®, G.M., Strepparava M.G., & Zorzi F. (2025, June). Driving Behaviors in Cognitive Agents: Preliminary Results of an Experimental Approach. In <i>WOA 2025 26th Workshop From Objects to Agents</i> (pp. 35-54).</summary>
            <pre class="p-2 mt-2">
@inproceedings{bani2025driving,
 author = {Bani, Marco and Bianco, Simone and Celona, Luigi and Napoletano, Paolo and Russo, Selena and Sarn√®, Giuseppe Maria Luigi and Strepparava, Maria Grazia and Zorzi, Federico},
 year = {2025},
 pages = {35-54},
 title = {Driving Behaviors in Cognitive Agents: An Experimental Approach},
 booktitle = {WOA 2025 26th Workshop From Objects to Agents},
}
                    </pre>
                    <button class="btn btn-primary copy-btn" data-latex="@inproceedings{bani2025driving, author = {Bani, Marco and Bianco, Simone and Celona, Luigi and Napoletano, Paolo and Russo, Selena and Sarn√®, Giuseppe Maria Luigi and Strepparava, Maria Grazia and Zorzi, Federico}, year = {2025}, title = {Driving Behaviors in Cognitive Agents: Preliminary Results of an Experimental Approach}, booktitle = {WOA 2025 26th Workshop From Objects to Agents} }">üìã Copy</button>
                </details>
            </li>
    <!-- Reference 1 -->
    <li class="Box Box--spacious p-3 mb-3">
        <details>
            <summary class="f4">üìñ Colombo, A., Celona, L., Bianco, S., Nocera, A., & Napoletano, P. (2024, September). Arm Gesture Recognition with Smartwatches. In <i>2024 IEEE 8th Forum on Research and Technologies for Society and Industry Innovation (RTSI)</i> (pp. 625-629). IEEE.</summary>
            <pre class="p-2 mt-2">
@inproceedings{colombo2024arm,
 author = {Colombo, Andrea and Celona, Luigi and Bianco, Simone and Nocera, Antonino and Napoletano, Paolo},
 year = {2024},
 title = {Arm Gesture Recognition With Smartwatches},
 organization = {IEEE},
 booktitle = {8th International Forum on Research and Technologies for Society and Industry (RTSI)},
}
                    </pre>
                    <button class="btn btn-primary copy-btn" data-latex="@inproceedings{colombo2024arm, author = {Colombo, Andrea and Celona, Luigi and Bianco, Simone and Nocera, Antonino and Napoletano, Paolo}, year = {2024}, title = {Arm Gesture Recognition With Smartwatches}, organization = {IEEE}, booktitle = {8th International Forum on Research and Technologies for Society and Industry (RTSI)} }">üìã Copy</button>
                </details>
            </li>


            <!-- Reference 2 -->
            <li class="Box Box--spacious p-3 mb-3">
                <details>
                    <summary class="f4">üìñ Celona, L., Bianco, S., & Napoletano, P. (2024). Cross-Camera Distracted Driver Classification through Feature Disentanglement and Contrastive Learning. <i>arXiv preprint arXiv:2411.13181.</i></summary>
                    <pre class="p-2 mt-2">
@article{celona2024cross,
 author = {Celona, Luigi and Bianco, Simone and Napoletano, Paolo},
 year = {2024},
 title = {Cross-Camera Distracted Driver Classification through Feature Disentanglement and Contrastive Learning},
 journal = {arXiv preprint arXiv:2411.13181}
}
                    </pre>
                    <button class="btn btn-primary copy-btn" data-latex="@article{celona2024cross, author = {Celona, Luigi and Bianco, Simone and Napoletano, Paolo}, year = {2024}, title = {Cross-Camera Distracted Driver Classification through Feature Disentanglement and Contrastive Learning}, journal = {arXiv preprint arXiv:2411.13181} }">üìã Copy</button>
                </details>
            </li>

            <!-- Reference 1 -->
            <li class="Box Box--spacious p-3 mb-3">
                <details>
                    <summary class="f4">üìñ Alchieri, L., Celona, L., & Bianco, S. (2023, September). Video-Based Emotion Estimation Using Deep Neural Networks: A Comparative Study. In <i>International Conference on Image Analysis and Processing</i> (pp. 255-269). Cham: Springer Nature Switzerland.</summary>
                    <pre class="p-2 mt-2">
@inproceedings{alchieri2023video,
 author = {Alchieri, Leonardo and Celona, Luigi and Bianco, Simone},
 year = {2024},
 pages = {255-269},
 title = {Video-Based Emotion Estimation Using Deep Neural Networks: A Comparative Study},
 publisher = {Springer Nature Switzerland},
 isbn = {978-3-031-51023-6},
 booktitle = {Image Analysis and Processing - ICIAP 2023 Workshops},
 doi = {10.1007/978-3-031-51023-6_22},
}
                    </pre>
                    <button class="btn btn-primary copy-btn" data-latex="@inproceedings{alchieri2023video, author = {Alchieri, Leonardo and Celona, Luigi and Bianco, Simone}, year = {2024}, pages = {255-269}, title = {Video-Based Emotion Estimation Using Deep Neural Networks: A Comparative Study}, publisher = {Springer Nature Switzerland}, isbn = {978-3-031-51023-6}, booktitle = {Image Analysis and Processing - ICIAP 2023 Workshops}, doi = {10.1007/978-3-031-51023-6_22} }">üìã Copy</button>
                </details>
            </li>


            <!-- Reference 3 -->
            <li class="Box Box--spacious p-3 mb-3">
                <details>
                    <summary class="f4">üìñ Bianco, S., Celona, L., Gallo, G. D., & Napoletano, P. (2023, September). A Platform for Multi-Modal Driver Behaviour Data Collection. In <i>2023 IEEE 13th International Conference on Consumer Electronics-Berlin (ICCE-Berlin)</i> (pp. 112-116). IEEE.</summary>
                    <pre class="p-2 mt-2">
@inproceedings{bianco2023platform,
  title={A Platform for Multi-Modal Driver Behaviour Data Collection},
  author={Bianco, Simone and Celona, Luigi and Gallo, Giovanni Donato and Napoletano, Paolo},
  booktitle={2023 IEEE 13th International Conference on Consumer Electronics-Berlin (ICCE-Berlin)},
  pages={112--116},
  year={2023},
  organization={IEEE}
}
                    </pre>
                    <button class="btn btn-primary copy-btn" data-latex="@inproceedings{bianco2023platform, title={A Platform for Multi-Modal Driver Behaviour Data Collection}, author={Bianco, Simone and Celona, Luigi and Gallo, Giovanni Donato and Napoletano, Paolo}, booktitle={2023 IEEE 13th International Conference on Consumer Electronics-Berlin (ICCE-Berlin)}, pages={112--116}, year={2023}, organization={IEEE} }">üìã Copy</button>
                </details>
            </li>

        </ul>
    </div>

<footer class="footer mt-5 py-4 bg-light text-center">
    <p>
        Project funded under the National Recovery and Resilience Plan (NRRP), Mission 4 Component 2 Investment 1.4 - Call for tender No. 1031 of 17 June 2022 of Italian Ministry of University and Research funded by the European Union ‚Äì NextGenerationEU.
    </p>
</footer>


</body>
</html>
